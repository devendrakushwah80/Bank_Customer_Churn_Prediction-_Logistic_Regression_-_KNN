# ðŸ¦ Bank Customer Churn Prediction  
### Logistic Regression & K-Nearest Neighbors (KNN)

---

## ðŸ“Œ Project Overview

Customer churn prediction is a critical problem in the banking industry.  
This project builds an **end-to-end machine learning pipeline** to predict whether a customer will **leave the bank or not**, using **two classification algorithms**:

- **Logistic Regression**
- **K-Nearest Neighbors (KNN)**

The notebook focuses strongly on **class imbalance handling**, **proper preprocessing**, and **model comparison**.

---

## ðŸŽ¯ Problem Statement

Given customer demographic and financial information, predict:

- `Exited = 1` â†’ Customer will leave the bank  
- `Exited = 0` â†’ Customer will stay  

This is a **binary classification problem** with **imbalanced classes**.

---

## ðŸ“Š Dataset Description

Key features used in the dataset:

- CreditScore  
- Geography  
- Gender  
- Age  
- Tenure  
- Balance  
- NumOfProducts  
- HasCrCard  
- IsActiveMember  
- EstimatedSalary  

ðŸŽ¯ **Target Variable**
- `Exited`

---

## ðŸ” Exploratory Data Analysis (EDA)

### âœ” Steps Performed
- Checked dataset shape and data types  
- Verified missing values and duplicates  
- Analyzed target class distribution  
- Performed basic numerical & categorical analysis  

### âš ï¸ Class Imbalance
The dataset is highly imbalanced:
- Majority class â†’ `Exited = 0`
- Minority class â†’ `Exited = 1`

This imbalance negatively impacts model learning if not handled.

---

## âš–ï¸ Handling Class Imbalance

To fix imbalance:
- Applied **manual random undersampling**
- Made both classes (`0` and `1`) equal in count
- Shuffled the dataset

âœ… This ensures fair learning for both classes.

---

## ðŸ›  Feature Engineering & Preprocessing

### ðŸ§¹ Dropped Irrelevant Columns
- `RowNumber`
- `CustomerId`
- `Surname`

### ðŸ”„ Encoding & Scaling (Using ColumnTransformer)
- **StandardScaler** â†’ Numerical features  
- **OneHotEncoder** â†’ Categorical features (`Geography`, `Gender`)

ðŸ“Œ Preprocessing was applied **after train-test split** to avoid data leakage.

---

## ðŸ¤– Models Implemented

### 1ï¸âƒ£ Logistic Regression
- Used as a **baseline classification model**
- Works well with scaled and encoded data
- Evaluated using:
  - Precision
  - Recall
  - F1-score
  - Accuracy

ðŸ“Œ Observations:
- Recall for churned customers improved after balancing
- Provides good interpretability

---

### 2ï¸âƒ£ K-Nearest Neighbors (KNN)
- Distance-based, non-parametric algorithm
- Value of **K selected using heuristic**:
K = âˆš(number of training samples)

- Requires proper feature scaling (handled in preprocessing)

ðŸ“Œ Observations:
- Sensitive to scaling and data distribution
- Captures non-linear decision boundaries better than Logistic Regression

---

## ðŸ“ˆ Model Evaluation & Comparison

- Models evaluated on **unseen test data**
- Used **classification report**:
  - Precision
  - Recall
  - F1-score
  - Accuracy

### Key Insight
> In churn prediction, **recall is more important than accuracy**, because missing a churned customer is costlier than a false alarm.

---

## ðŸ§  Key Learnings

- Accuracy alone is misleading for imbalanced datasets  
- Logistic Regression:
  - Stable
  - Interpretable
- KNN:
  - Flexible
  - Sensitive to preprocessing
- **Data quality & imbalance handling matter more than model choice**

---

## ðŸ§ª Technologies Used

- Python  
- NumPy  
- Pandas  
- Matplotlib  
- Seaborn  
- Scikit-learn  
- Jupyter Notebook  

---

## ðŸš€ Future Improvements

- Use **SMOTE / ADASYN** instead of undersampling  
- Add **ROCâ€“AUC & Precisionâ€“Recall curves**  
- Hyperparameter tuning:
  - `C` for Logistic Regression  
  - `K` and distance metric for KNN  
- Compare with:
  - Random Forest  
  - XGBoost  

---

## ðŸ“‚ Project Structure
ðŸ“¦ Bank-Churn-Prediction
â”£ ðŸ“œ Bank_Churn_prediction.ipynb
â”£ ðŸ“œ churn.csv
â”— ðŸ“œ README.md

---

## âœ… Conclusion

This project demonstrates a **real-world machine learning workflow**:

- Handling imbalanced data  
- Proper preprocessing pipelines  
- Training **multiple classification algorithms**  
- Business-oriented model evaluation  

A strong foundation for **industry-level churn prediction problems** ðŸš€
